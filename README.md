# 用于对话系统的中英文语料
Datasets for Training Chatbot System
<br>本项目收集了一些从网络中找到的用于训练中文（英文）聊天机器人的对话语料

### 公开语料
搜集到的一些数据集如下，点击链接可以进入原始地址

1. [dgk_shooter_min.conv.zip](https://github.com/rustch3n/dgk_lost_conv)
<br>中文电影对白语料，噪音比较大，许多对白问答关系没有对应好

2. [The NUS SMS Corpus](https://github.com/kite1988/nus-sms-corpus)
<br>包含中文和英文短信息语料，据说是世界最大公开的短消息语料

3. [ChatterBot中文基本聊天语料](https://github.com/gunthercox/ChatterBot/tree/master/chatterbot/corpus/data/chinese)
<br>ChatterBot聊天引擎提供的一点基本中文聊天语料，量很少，但质量比较高

4. [Datasets for Natural Language Processing](https://github.com/karthikncode/nlp-datasets)
<br>这是他人收集的自然语言处理相关数据集，主要包含Question Answering，Dialogue Systems， Goal-Oriented Dialogue Systems三部分，都是英文文本。可以使用机器翻译为中文，供中文对话使用

5. [小黄鸡](https://github.com/rustch3n/dgk_lost_conv/tree/master/results)
<br>据传这就是小黄鸡的语料：xiaohuangji50w_fenciA.conv.zip （已分词） 和 xiaohuangji50w_nofenci.conv.zip （未分词）

6. [白鹭时代中文问答语料](https://github.com/Samurais/egret-wenda-corpus)
<br>由白鹭时代官方论坛问答板块10,000+ 问题中，选择被标注了“最佳答案”的纪录汇总而成。人工review raw data，给每一个问题，一个可以接受的答案。目前，语料库只包含2907个问答。([备份](./egret-wenda-corpus.zip))

7. [Chat corpus repository](https://github.com/Marsan-Ma/chat_corpus)
<br>chat corpus collection from various open sources
<br>包括：开放字幕、英文电影字幕、中文歌词、英文推文

### 未公开语料

这部分语料，网络上有所流传，但由于我们能力所限，或者原作者并未公开，暂时未获取。只是列举出来，供以后继续搜寻。

1. 微软小冰

### 版权

所有原始语料归原作者所有

### 联系

[何云超](yunchaohe@gmail.com)
weibo: [@Yunchao_He](http://weibo.com/heyunchao)